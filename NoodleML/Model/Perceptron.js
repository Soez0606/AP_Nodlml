/**********************************************************
 *      _   _                 _ _     ___  ___ _
 *     | \ | |               | | |    |  \/  || |
 *     |  \| | ___   ___   __| | | ___| .  . || |
 *     | . ` |/ _ \ / _ \ / _` | |/ _ \ |\/| || |
 *     | |\  | (_) | (_) | (_| | |  __/ |  | || |____
 *     \_| \_/\___/ \___/ \__,_|_|\___\_|  |_/\_____/
 *
 *      üçú Think with noodles. Code AI with neurons.
 *       -------------------------------------------
 *            Minimal Neural Network Framework
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program. If not, see <https://www.gnu.org/licenses/>.
 * 
 * ¬© 2025 S√©bastien MARCHAND
 **********************************************************/

/**
 * @class Perceptron
 * @classdesc Impl√©mentation d‚Äôun perceptron simple √† n entr√©es avec apprentissage supervis√©.
 *
 * Ce perceptron utilise une fonction d‚Äôactivation √† seuil (step function).
 * Il peut √™tre entra√Æn√© √† l‚Äôaide de la r√®gle de correction bas√©e sur l‚Äôerreur.
 *
 * Exemple typique d‚Äôutilisation :
 * - Classification lin√©aire binaire
 * - Apprentissage de fonctions logiques (AND, OR, etc.)
 * - Visualisation p√©dagogique des r√©seaux de neurones
 */
class Perceptron {
  /**
   * Cr√©e une instance du perceptron.
   *
   * Initialise le perceptron avec un nombre d'entr√©es donn√© et attribue des poids
   * al√©atoires √† chacune de ces entr√©es, ainsi qu'un biais al√©atoire. Un seuil d'activation
   * est fix√© √† 0 par d√©faut. Le param√®tre disableThreshold est pr√©vu pour indiquer
   * si l'activation par seuil doit √™tre d√©sactiv√©e, bien que dans l'initialisation,
   * la valeur soit forc√©e √† false.
   *
   * @param {number} inputSize - Nombre d'entr√©es du perceptron.
   * @param {number} [learningRate=0.1] - Taux d'apprentissage utilis√© pour la mise √† jour des poids.
   * @param {boolean} [disableThreshold=false] - Indique si le seuil d'activation doit √™tre d√©sactiv√©.
   */
  constructor(inputSize, learningRate = 0.1, disableThreshold = false) {
    this.learningRate = learningRate;
    this.weights = Array.from({ length: inputSize }, () => Math.random() * 2 - 1); // [-1, 1]
    this.bias = Math.random() * 2 - 1;
    this.activationThreshold = 0;
    this.disableThreshold = disableThreshold;
    this.name = "Perceptron";
  }

  /**
    * Fonction d‚Äôactivation de type seuil.
    *
    * @param {number} x - Entr√©e brute (somme pond√©r√©e + biais).
    * @returns {number} 1 si x > 0, sinon 0.
    */
  activate(x) {

    if (this.disableThreshold) {
      // Fonction d'activation lin√©aire born√©e
      return ActivationFunctions.linearBounded.f(x);
    }
    else {
      // Fonction d'activation de type seuillage binaire standard 
      // d'un perceptron simple
      return ActivationFunctions.binary.f(x);
    }
  }

  /**
    * Pr√©dit la sortie binaire du perceptron √† partir d‚Äôun vecteur d‚Äôentr√©e.
    *
    * @param {number[]} input - Tableau d‚Äôentr√©es num√©riques.
    * @returns {number} 0 ou 1 selon le r√©sultat de la fonction d‚Äôactivation.
    */
  predict(input) {

    let sum = this.bias;
    for (let i = 0; i < input.length; i++) {
      sum += this.weights[i] * input[i];
    }
    
    return this.activate(sum);
  }

  /**
    * Entra√Æne le perceptron √† l‚Äôaide d‚Äôun exemple d‚Äôentr√©e et d‚Äôune sortie attendue.
    * Met √† jour les poids et le biais en fonction de l‚Äôerreur observ√©e.
    *
    * @param {number[]} input - Tableau d‚Äôentr√©es num√©riques.
    * @param {number} target - Valeur cible (0 ou 1).
    */
  train(input, target) {
    const prediction = this.predict(input);
    const error = target - prediction;

    for (let i = 0; i < input.length; i++) {
      this.weights[i] += this.learningRate * error * input[i];
    }

    this.bias += this.learningRate * error;
  }

  /**
   * R√©initialise les poids et le biais avec des valeurs al√©atoires
   */
  reset() {
    this.weights = this.weights.map(() => Math.random() * 2 - 1);
    this.bias = Math.random() * 2 - 1;
  }

  /**
  * Retourne une copie des poids actuels du perceptron.
  *
  * @returns {number[]} Un tableau contenant les poids.
  */
  getWeights() {
    return [...this.weights];
  }

  /**
   * Retourne la valeur actuelle du biais.
   *
   * @returns {number} Le biais.
   */
  getBias() {
    return this.bias;
  }

  /**
   * D√©finit les poids du perceptron.
   * Les poids existants sont remplac√©s par une copie du tableau fourni.
   *
   * @param {number[]} weights - Un tableau contenant les nouveaux poids.
   */
  setWeights(weights) {
    this.weights = [...weights];
  }

  /**
   * D√©finit la valeur du biais du perceptron.
   *
   * @param {number} bias - La nouvelle valeur du biais.
   */
  setBias(bias) {
    this.bias = bias;
  }

  /**
   * D√©finit le seuil d'activation du perceptron.
   *
   * @param {number} treshold - La nouvelle valeur du seuil d'activation.
   */
  setActivationThreshold(treshold) {
    this.activationThreshold = treshold;
  }

  /**
   * D√©sactive ou active le seuil d'activation. Cette possibilit√© est int√©ressante 
   * pour visualiser le comportement du perceptron sans l'influence du seuil 
   * (visualisation 3D).
   * 
   * @param {boolean} disable - true pour d√©sactiver le seuil, false pour l'activer.
   * 
   * @returns {void}
   */
  setDisableThreshold(disable) {
    this.disableThreshold = disable;
  }

  /**
   * @brief Entra√Æne le perceptron sur un ensemble d'exemples √©tiquet√©s.
   *
   * Cette m√©thode applique la r√®gle d'apprentissage du perceptron sur
   * plusieurs it√©rations (epochs) pour ajuster les poids et le biais.
   * √Ä chaque epoch, l'ensemble des exemples est trait√© s√©quentiellement
   * (avec possibilit√© de les m√©langer avant chaque passage).
   *
   * @param {Array<Object>} data 
   *        Tableau d'objets de la forme :
   *        [
   *          { x: [Number, Number, ...], y: Number },
   *          ...
   *        ]
   *        o√π `x` est le vecteur d'entr√©e et `y` la sortie attendue (0 ou 1).
   *
   * @param {Number} [epochs=20]
   *        Nombre de passages complets sur l'ensemble de donn√©es.
   *
   * @param {Boolean} [shuffle=true]
   *        Si vrai, m√©lange l'ordre des exemples √† chaque epoch
   *        afin d'√©viter un biais li√© √† l'ordre des donn√©es.
   *
   * @return {void}
   *
   * @note L'algorithme converge uniquement si les donn√©es
   *       sont lin√©airement s√©parables.
   * @note La m√©thode `train()` est appel√©e en interne pour chaque exemple.
   * @warning Pour un bon apprentissage, normalisez les donn√©es d'entr√©e.
   */
  fit(data, epochs = 20, shuffle = true) {
    for (let e = 0; e < epochs; e++) {
      if (shuffle) {
        data = data.sort(() => Math.random() - 0.5);
      }
      for (const { x, y } of data) {
        this.train(x, y);
      }
    }
  }
}