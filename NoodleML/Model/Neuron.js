/**********************************************************
 *      _   _                 _ _     ___  ___ _
 *     | \ | |               | | |    |  \/  || |
 *     |  \| | ___   ___   __| | | ___| .  . || |
 *     | . ` |/ _ \ / _ \ / _` | |/ _ \ |\/| || |
 *     | |\  | (_) | (_) | (_| | |  __/ |  | || |____
 *     \_| \_/\___/ \___/ \__,_|_|\___\_|  |_/\_____/
 *
 *      üçú Think with noodles. Code AI with neurons.
 *       -------------------------------------------
 *            Minimal Neural Network Framework
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program. If not, see <https://www.gnu.org/licenses/>.
 * 
 * ¬© 2025 S√©bastien MARCHAND
 **********************************************************/

/**
 * @class Neuron
 * @extends Perceptron
 * @classdesc Repr√©sente un neurone standard avec connexions explicites
 * et fonction d'activation continue (sigmo√Øde, tanh, relu, etc.).
 */
class Neuron extends Perceptron {

    /**
     * Initialise un neurone avec des connexions sp√©cifiques.
     * Si aucune connexion n‚Äôest pr√©cis√©e, on suppose une connexion compl√®te via inputSize.
     *
     * @param {number} inputSize - Nombre total d'entr√©es possibles (uniquement utilis√© si `connections` est vide).
     * @param {number} [learningRate=0.1] - Taux d'apprentissage.
     * @param {object} [activation=ActivationFunctions.sigmoid] - Fonction d'activation.
     * @param {Array<{index: number, weight: number}>} [connections=[]] - Connexions explicites.
     */
    constructor(inputSize, learningRate = 0.1, activation = ActivationFunctions.sigmoid, connections = []) {

        const weights = connections.length > 0
            ? connections.map(conn => conn.weight)
            : Array.from({ length: inputSize }, () => Math.random() * 2 - 1);

        super(weights.length, learningRate);

        /**
         * @type {Array<{index: number, weight: number}>}
         * Connexions actives de ce neurone vers les entr√©es.
         */
        this.connections = connections.length > 0
            ? connections
            : weights.map((w, i) => ({ index: i, weight: w }));

        this.activation = activation;
    }

    /**
     * Calcule la sortie du neurone √† partir des entr√©es sp√©cifi√©es.
     *
     * @param {number[]} inputs - Entr√©es externes au neurone.
     * @returns {number} Sortie activ√©e.
     */
    predict(inputs) {
        let sum = this.bias;
        for (const { index, weight } of this.connections) {
            if (index >= inputs.length) {
                throw new Error(`Index ${index} hors des bornes d'entr√©e.`);
            }
            sum += inputs[index] * weight;
        }
        return this.activate(sum);
    }

    /**
     * Applique la fonction d‚Äôactivation au r√©sultat.
     * @param {number} sum - Somme pond√©r√©e des entr√©es + biais.
     * @returns {number} Sortie activ√©e.
     */
    activate(sum) {
        return this.activation.f(sum);
    }

    /**
     * Calcule la d√©riv√©e de la fonction d‚Äôactivation.
     * @param {number} sum - Somme pond√©r√©e des entr√©es + biais.
     * @returns {number} D√©riv√©e de l'activation.
     */
    activationDerivative(sum) {
        return this.activation.df(sum);
    }

    /**
     * Change dynamiquement la fonction d‚Äôactivation.
     * @param {object} activation - Objet fonctionnel {f, df}.
     */
    setActivationFunction(activation) {
        this.activation = activation;
    }

    /**
     * Ajoute dynamiquement une connexion √† ce neurone.
     * @param {number} index - Indice de l‚Äôentr√©e source.
     * @param {number|null} [weight=null] - Poids de la connexion (al√©atoire si null).
     */
    addConnection(index, weight = null) {
        this.connections.push({
            index,
            weight: weight !== null ? weight : Math.random() * 2 - 1
        });
    }

    /**
     * Met √† jour tous les poids des connexions existantes.
     * @param {number[]} weights - Nouveaux poids.
     */
    setWeights(weights) {
        if (weights.length !== this.connections.length) {
            throw new Error("Le nombre de poids ne correspond pas au nombre de connexions.");
        }
        for (let i = 0; i < weights.length; i++) {
            this.connections[i].weight = weights[i];
        }
    }

    /**
     * Retourne tous les poids actuels.
     * @returns {number[]} Tableau des poids.
     */
    getWeights() {
        return this.connections.map(conn => conn.weight);
    }
}